{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"3azDZOMraR1m"},"outputs":[],"source":["import tensorflow as tf\n","import keras\n","from keras.models import Model\n","from keras.layers import Conv2D, Dense, Input, Reshape, Lambda, Layer, Flatten\n","from keras import backend as K\n","import numpy as np\n","from tqdm import tqdm\n","\n","from keras import initializers, regularizers\n","from keras.utils import to_categorical\n","from keras.layers.core import Activation\n","import pathlib\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from datetime import datetime\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["import pathlib\n","dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n","data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\n","data_dir = pathlib.Path(data_dir)\n","\n","batch_size = 64\n","img_height = 56\n","img_width = 56"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BoDFVXqwCprW","executionInfo":{"status":"ok","timestamp":1678173687282,"user_tz":-120,"elapsed":17091,"user":{"displayName":"Trâm Mai","userId":"14047835568893253890"}},"outputId":"e7bb3667-a554-4f12-d2e7-a03c0c81c7d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n","228813984/228813984 [==============================] - 8s 0us/step\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":367,"status":"ok","timestamp":1678173692084,"user":{"displayName":"Trâm Mai","userId":"14047835568893253890"},"user_tz":-120},"id":"0Nquno7uiDTw","outputId":"11db2fba-3cc7-4435-ffac-7e6965cd7b3e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2939 images belonging to 5 classes.\n","Found 731 images belonging to 5 classes.\n"]}],"source":["gen = ImageDataGenerator(rescale=1./255, validation_split=0.2, rotation_range=8, width_shift_range=0.08, shear_range=0.3, height_shift_range=0.08, zoom_range=0.08)\n","\n","train_ds = gen.flow_from_directory(\n","    data_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    shuffle=True,\n","    seed=123,\n","    subset='training',\n","    class_mode='sparse'\n",")\n","\n","val_ds = gen.flow_from_directory(\n","    data_dir,\n","    target_size=(img_height, img_width),\n","    class_mode='sparse',\n","    batch_size=batch_size,\n","    shuffle=True,\n","    seed=123,\n","    subset='validation'\n",")\n","\n","num_classes = len(train_ds.class_indices)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uaDPaup1m-FQ"},"outputs":[],"source":["checkpoint_path = 'drive/My Drive/TIES4911/capsule_network/checkpoint'\n","model_weight_path = 'drive/My Drive/TIES4911/capsule_network/model_weight'\n","# File writer\n","stamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","scalar_logdir = 'drive/My Drive/TIES4911/capsule_network/logs/scalars/%s' % stamp\n","file_writer = tf.summary.create_file_writer(scalar_logdir + \"/metrics\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SWpD6N6dnKqa"},"outputs":[],"source":["dataset_len = 1000\n","training_dataset_size = batch_size * dataset_len\n","testing_dataset_size = batch_size * dataset_len * 0.2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"62XYhR_xaoo5"},"outputs":[],"source":["class CapsuleNetwork(tf.keras.Model):\n","    def __init__(self, no_of_conv_kernels, no_of_primary_capsules, primary_capsule_vector, no_of_secondary_capsules, secondary_capsule_vector, r):\n","        super(CapsuleNetwork, self).__init__()\n","        self.no_of_conv_kernels = no_of_conv_kernels\n","        self.no_of_primary_capsules = no_of_primary_capsules\n","        self.primary_capsule_vector = primary_capsule_vector\n","        self.no_of_secondary_capsules = no_of_secondary_capsules\n","        self.secondary_capsule_vector = secondary_capsule_vector\n","        self.r = r\n","        \n","        with tf.name_scope(\"Variables\") as scope:\n","            self.convolution = tf.keras.layers.Conv2D(self.no_of_conv_kernels, 48, strides=[1,1], kernel_initializer=\"he_normal\")\n","            self.convolution2 = tf.keras.layers.BatchNormalization(axis=3)\n","            self.convolution3 = tf.keras.layers.Activation('relu')\n","            self.primary_capsule = tf.keras.layers.Conv2D(self.no_of_primary_capsules * self.primary_capsule_vector, [9,9], strides=[2,2], name=\"PrimaryCapsule\")\n","            self.w = tf.Variable(tf.random_normal_initializer()(shape=[1, 64, self.no_of_secondary_capsules, self.secondary_capsule_vector, self.primary_capsule_vector]), dtype=tf.float32, name=\"PoseEstimation\", trainable=True)\n","            self.dense_1 = tf.keras.layers.Dense(units = 512, activation='relu')\n","            self.dense_2 = tf.keras.layers.Dense(units = 1024, activation='relu')\n","            self.dense_3 = tf.keras.layers.Dense(units = 9408, activation='sigmoid', dtype='float32')\n","        \n","    def build(self, input_shape):\n","        pass\n","        \n","    def squash(self, s):\n","        with tf.name_scope(\"SquashFunction\") as scope:\n","            s_norm = tf.norm(s, axis=-1, keepdims=True)\n","            return tf.square(s_norm)/(1 + tf.square(s_norm)) * s/(s_norm + epsilon)\n","    \n","    @tf.function\n","    def call(self, inputs):\n","        input_x, y = inputs\n","        \n","        x = self.convolution(input_x) # x.shape: (None, 9, 9, 256)\n","        x = self.convolution2(x)\n","        x = self.convolution3(x)\n","        x = self.primary_capsule(x) # x.shape: (None, 1, 1, 512)\n","\n","        print('output x: ', x.shape)\n","        \n","        with tf.name_scope(\"CapsuleFormation\") as scope:\n","            u = tf.reshape(x, (-1, self.no_of_primary_capsules * x.shape[1] * x.shape[2], 8)) # u.shape: (None, 64, 8)\n","            u = self.squash(u)\n","            u = tf.expand_dims(u, axis=-2) # u.shape: (None, 64, 1, 8)\n","            u = tf.expand_dims(u, axis=-1) # u.shape: (None, 64, 1, 8, 1)\n","            u_hat = tf.matmul(self.w, u) # u_hat.shape: (None, 64, 5, 16, 1)\n","            u_hat = tf.squeeze(u_hat, [4]) # u_hat.shape: (None, 64, 5, 16)\n","\n","        \n","        with tf.name_scope(\"DynamicRouting\") as scope:\n","            b = tf.zeros((input_x.shape[0], self.no_of_primary_capsules * x.shape[1] * x.shape[2], self.no_of_secondary_capsules, 1)) # b.shape: (None, 64, 5, 1)\n","            for i in range(self.r): # self.r = 3\n","                c = tf.nn.softmax(b, axis=-2) # c.shape: (None, 64, 5, 1)\n","                s = tf.reduce_sum(tf.multiply(c, u_hat), axis=1, keepdims=True) # s.shape: (None, 1, 5, 16)\n","                v = self.squash(s) # v.shape: (None, 1, 5, 16)\n","                agreement = tf.squeeze(tf.matmul(tf.expand_dims(u_hat, axis=-1), tf.expand_dims(v, axis=-1), transpose_a=True), [4]) # agreement.shape: (None, 64, 5, 1)\n","                # Before matmul following intermediate shapes are present, they are not assigned to a variable but just for understanding the code.\n","                # u_hat.shape (Intermediate shape) : (None, 64, 5, 16, 1)\n","                # v.shape (Intermediate shape): (None, 1, 5, 16, 1)\n","                # Since the first parameter of matmul is to be transposed its shape becomes:(None, 64, 5, 1, 16)\n","                # Now matmul is performed in the last two dimensions, and others are broadcasted\n","                # Before squeezing we have an intermediate shape of (None, 64, 5, 1, 1)\n","                b += agreement\n","        \n","        with tf.name_scope(\"Masking\") as scope:\n","            print('y: ', y.shape)\n","            y = tf.expand_dims(y, axis=-1) # y.shape: (None, 5, 1)\n","            y = tf.expand_dims(y, axis=1) # y.shape: (None, 1, 5, 1)\n","            mask = tf.cast(y, dtype=tf.float32) # mask.shape: (None, 1, 5, 1)\n","            print('v: ', v.shape)\n","            print('mask; ', mask.shape)\n","            v_masked = tf.multiply(mask, v) # v_masked.shape: (None, 1, 5, 16)\n","            print('v_masked; ', v_masked.shape)\n","            \n","        with tf.name_scope(\"Reconstruction\") as scope:\n","            v_ = tf.reshape(v_masked, [-1, self.no_of_secondary_capsules * self.secondary_capsule_vector]) # v_.shape: (None, 80)\n","            print('v_: ', v_.shape)\n","            reconstructed_image = self.dense_1(v_) # reconstructed_image.shape: (None, 512)\n","            reconstructed_image = self.dense_2(reconstructed_image) # reconstructed_image.shape: (None, 1024)\n","            reconstructed_image = self.dense_3(reconstructed_image) # reconstructed_image.shape: (None, 9408)\n","            print('reconstructed_image: ', reconstructed_image.shape)\n","        \n","        return v, reconstructed_image\n","    @tf.function\n","    def predict_capsule_output(self, inputs):\n","        x = self.convolution(inputs)\n","        x = self.convolution2(x)\n","        x = self.convolution3(x)\n","        x = self.primary_capsule(x)\n","        \n","        with tf.name_scope(\"CapsuleFormation\") as scope:\n","            u = tf.reshape(x, (-1, self.no_of_primary_capsules * x.shape[1] * x.shape[2], 8))\n","            u = self.squash(u)\n","            u = tf.expand_dims(u, axis=-2)\n","            u = tf.expand_dims(u, axis=-1)\n","            u_hat = tf.matmul(self.w, u)\n","            u_hat = tf.squeeze(u_hat, [4])\n","\n","        \n","        with tf.name_scope(\"DynamicRouting\") as scope:\n","            b = tf.zeros((inputs.shape[0], self.no_of_primary_capsules * x.shape[1] * x.shape[2], self.no_of_secondary_capsules, 1))\n","            for i in range(self.r):\n","                c = tf.nn.softmax(b, axis=-2)\n","                s = tf.reduce_sum(tf.multiply(c, u_hat), axis=1, keepdims=True)\n","                v = self.squash(s)\n","                agreement = tf.squeeze(tf.matmul(tf.expand_dims(u_hat, axis=-1), tf.expand_dims(v, axis=-1), transpose_a=True), [4])\n","                b += agreement\n","\n","        return v"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8PNNpuSsbCGy"},"outputs":[],"source":["def safe_norm(v, axis=-1, epsilon=1e-7):\n","    v_ = tf.reduce_sum(tf.square(v), axis = axis, keepdims=True)\n","    return tf.sqrt(v_ + epsilon)\n","\n","def get_val_loss(x,y):\n","    y_one_hot = tf.one_hot(y, depth=num_classes)\n","    v, reconstructed_image = model([x, y_one_hot])\n","\n","    print('y: ', y)\n","    print('pred: ', normalize_prediction(v))\n","    print('sum: ', sum(y==normalize_prediction(v)))\n","    loss = loss_function(v, reconstructed_image, y_one_hot, x)\n","    val_acc_metric(y, normalize_prediction(v))\n","    return loss\n","\n","def train(x,y):\n","    y_one_hot = tf.one_hot(y, depth=num_classes)\n","    #print('y_one_hot: ', y_one_hot.shape)\n","    with tf.GradientTape() as tape:\n","        v, reconstructed_image = model([x, y_one_hot])\n","        loss = loss_function(v, reconstructed_image, y_one_hot, x)\n","    grad = tape.gradient(loss, model.trainable_variables)\n","    optimizer.apply_gradients(zip(grad, model.trainable_variables))\n","\n","    print('y: ', y)\n","    print('pred: ', normalize_prediction(v))\n","    print('sum: ', sum(y==normalize_prediction(v)))\n","    train_acc_metric(y, normalize_prediction(v))\n","    return loss\n","\n","def loss_function(v, reconstructed_image, y, y_image):   \n","    prediction = safe_norm(v)\n","    prediction = tf.reshape(prediction, [-1, no_of_secondary_capsules])\n","    \n","    print('prediction: ', prediction.shape)\n","    left_margin = tf.square(tf.maximum(0.0, m_plus - prediction))\n","    right_margin = tf.square(tf.maximum(0.0, prediction - m_minus))\n","    \n","    l = tf.add(y * left_margin, lambda_ * (1.0 - y) * right_margin)\n","\n","    margin_loss = tf.reduce_mean(tf.reduce_sum(l, axis=-1))\n","    \n","    y_image_flat = tf.reshape(y_image, [-1, np.prod(y_image.shape[1:])])\n","    reconstruction_loss = tf.reduce_mean(tf.square(y_image_flat - reconstructed_image))\n","    \n","    loss = tf.add(margin_loss, alpha * reconstruction_loss)    \n","    \n","    return loss\n","\n","def normalize_prediction(v):\n","  pred = safe_norm(v)\n","  pred = tf.squeeze(pred, [1])\n","  return np.argmax(pred, axis=1)[:,0]\n","\n","def predict(model, x):\n","  v = model.predict_capsule_output(x)\n","  return normalize_prediction(v)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g-UfQ-ZIafZk"},"outputs":[],"source":["# Parameters Based on Paper\n","epsilon = K.epsilon()\n","m_plus = 0.9\n","m_minus = 0.1\n","lambda_ = 0.5\n","alpha = 0.0005\n","epochs = 50\n","no_of_secondary_capsules = num_classes\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n","train_acc_metric = tf.keras.metrics.Accuracy()\n","val_acc_metric = tf.keras.metrics.Accuracy()\n","\n","params = {\n","    \"no_of_conv_kernels\": 256,\n","    \"no_of_primary_capsules\": 64,\n","    \"no_of_secondary_capsules\": num_classes,\n","    \"primary_capsule_vector\": 8,\n","    \"secondary_capsule_vector\": 16,\n","    \"r\":3,\n","}\n","\n","model = CapsuleNetwork(**params)\n","#model.load_weights(model_weight_path + '-epoch 4')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hGUxLl10bFdo","outputId":"5ac0598c-57ac-43df-c3c0-8be92354df93","executionInfo":{"status":"ok","timestamp":1678182601545,"user_tz":-120,"elapsed":12574,"user":{"displayName":"Trâm Mai","userId":"14047835568893253890"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1/1:   0%|          | 0/1000 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["output x:  (64, 1, 1, 512)\n","y:  (64, 5)\n","v:  (64, 1, 5, 16)\n","mask;  (64, 1, 5, 1)\n","v_masked;  (64, 1, 5, 16)\n","v_:  (64, 80)\n","reconstructed_image:  (64, 9408)\n","output x:  (64, 1, 1, 512)\n","y:  (64, 5)\n","v:  (64, 1, 5, 16)\n","mask;  (64, 1, 5, 1)\n","v_masked;  (64, 1, 5, 16)\n","v_:  (64, 80)\n","reconstructed_image:  (64, 9408)\n","prediction:  (64, 5)\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch 1/1:   0%|          | 1/1000 [00:11<3:08:58, 11.35s/it]"]},{"output_type":"stream","name":"stdout","text":["y:  [0. 4. 2. 2. 1. 0. 2. 4. 1. 3. 3. 4. 1. 2. 0. 2. 1. 0. 4. 3. 0. 2. 3. 1.\n"," 2. 1. 1. 3. 3. 3. 1. 2. 1. 2. 2. 3. 2. 1. 0. 3. 0. 0. 0. 0. 4. 2. 1. 1.\n"," 3. 1. 3. 4. 0. 3. 3. 1. 1. 1. 4. 3. 1. 4. 1. 2.]\n","pred:  [4 4 4 4 0 4 0 0 4 4 0 4 3 3 0 0 4 3 4 4 4 4 4 4 4 4 4 3 3 4 4 3 4 0 0 4 4\n"," 0 4 4 3 4 4 0 0 4 4 4 4 3 4 3 3 4 4 4 4 4 4 3 4 4 4 0]\n","sum:  10\n","train_ds len:  64\n","train_ds loss step:  1\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/1:   0%|          | 1/1000 [00:12<3:31:24, 12.70s/it, loss :0.75446194, accuracy :0.15625, val_loss :0.449345, val_accuracy :0.1875 Checkpoint Saved]"]},{"output_type":"stream","name":"stdout","text":["y:  [1. 2. 3. 0. 1. 3. 1. 1. 0. 3. 4. 2. 4. 0. 3. 0. 3. 0. 0. 2. 4. 3. 2. 0.\n"," 2. 4. 2. 2. 0. 3. 1. 1. 2. 4. 4. 2. 4. 1. 2. 4. 1. 3. 2. 1. 4. 1. 2. 4.\n"," 0. 3. 0. 1. 3. 3. 0. 1. 1. 4. 1. 1. 1. 1. 3. 4.]\n","pred:  [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n"," 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n","sum:  12\n","prediction:  (64, 5)\n","val_ds len:  64\n","val_ds loss step:  1\n","loss:  [0.75446194]\n","val_loss:  [0.449345]\n","accuracy:  [0.15625]\n","val_accuracy:  [0.1875]\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["epochs =  1\n","\n","checkpoint = tf.train.Checkpoint(model=model)\n","\n","losses = []\n","accuracy = []\n","val_losses = []\n","val_accuary = []\n","for i in range(1, epochs+1, 1):\n","  loss = 0\n","  val_loss = 0\n","\n","  with tqdm(total=dataset_len) as pbar:\n","    description = \"Epoch \" + str(i) + \"/\" + str(epochs)\n","    pbar.set_description_str(description)\n","\n","    step_per_epoch = 0\n","    len = 0\n","    for X_batch, y_batch in train_ds:\n","      step_per_epoch += 1\n","      len += X_batch.shape[0]\n","      loss += train(X_batch,y_batch)\n","\n","      pbar.update(1)\n","\n","      if step_per_epoch == dataset_len:\n","        break        \n","      #break\n","\n","    model.save_weights(model_weight_path + '-epoch ' + str(i))\n","    checkpoint.save(checkpoint_path)\n","\n","    print('train_ds len: ', len)\n","    print('train_ds loss step: ', step_per_epoch)\n","    #loss /= len(dataset)\n","    loss /= step_per_epoch\n","    losses.append(loss.numpy())\n","\n","    #print_statement = \"Loss :\" + str(loss.numpy()) + \" Evaluating Accuracy ...\"\n","    #pbar.set_postfix_str(print_statement)\n","\n","    train_acc = train_acc_metric.result()\n","    train_acc_metric.reset_states()\n","    accuracy.append(train_acc.numpy())\n","\n","    step_per_epoch = 0\n","    len = 0\n","    for X_batch, y_batch in val_ds:\n","        step_per_epoch += 1\n","        len += X_batch.shape[0]\n","        val_loss += get_val_loss(X_batch,y_batch)\n","\n","        if step_per_epoch == dataset_len * 0.2:\n","            break        \n","        #break\n","    print('val_ds len: ', len)\n","    print('val_ds loss step: ', step_per_epoch)    \n","    #loss /= len(dataset)\n","    val_loss /= step_per_epoch\n","    val_losses.append(val_loss.numpy())\n","\n","    val_acc = val_acc_metric.result()\n","    val_acc_metric.reset_states()   \n","    val_accuary.append(val_acc.numpy())     \n","    \n","    with file_writer.as_default():\n","      tf.summary.scalar('loss', data=loss.numpy(), step=i)\n","      tf.summary.scalar('val_loss', data=val_loss.numpy(), step=i)\n","      tf.summary.scalar('accuracy', data=accuracy[-1], step=i)\n","      tf.summary.scalar('val_accuracy', data=val_accuary[-1], step=i)\n","    \n","    print_statement = \"loss :\" + str(loss.numpy()) + \", accuracy :\" + str(accuracy[-1]) + \", val_loss :\" + str(val_loss.numpy()) + \", val_accuracy :\" + str(val_accuary[-1])\n","    pbar.set_postfix_str(print_statement)\n","\n","model.save_weights(model_weight_path) \n","#model.save('./capsule_network/flower_photos_model')\n","\n","print('loss: ', losses)\n","print('val_loss: ', val_losses)\n","print('accuracy: ', accuracy)\n","print('val_accuracy: ', val_accuary)"]},{"cell_type":"code","source":["loss:  [0.4398154, 0.35719398, 0.3411422, 0.3387112, 0.33299312]\n","val_loss:  [0.39099583, 0.35036805, 0.33167157, 0.32724562, 0.32251003]\n","accuracy:  [0.26430517, 0.39441416, 0.4332425, 0.4294959, 0.4400545]\n","val_accuracy:  [0.39918256, 0.4414169, 0.4509537, 0.4509537, 0.45912805]"],"metadata":{"id":"JNUs7uAqd5zd"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1ScWXm5ixSgXUPsLTzX81xcvbwIm71TiR","authorship_tag":"ABX9TyPwkLeiF3nrip4a04KkIyuY"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}