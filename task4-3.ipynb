{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1P0O3jvKsXmCfWt_4iglci7oOCmqn3hTv","authorship_tag":"ABX9TyN3er4+J1lIC+hrm8C5sUFB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!unzip 'drive/My Drive/TIES4911/task4/apparel-images-dataset.zip' -d '/content/drive/My Drive/TIES4911/task4/apparel-images-dataset'"],"metadata":{"id":"O5EK-aG-rRVp"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":27,"metadata":{"id":"LEKIjd_vd2J0","executionInfo":{"status":"ok","timestamp":1677752575515,"user_tz":-120,"elapsed":371,"user":{"displayName":"Trâm Mai","userId":"14047835568893253890"}}},"outputs":[],"source":["import tensorflow as tf\n","import pathlib\n","from tensorflow.keras.applications import mobilenet_v2\n","from keras import Input, Model, layers\n","from datetime import datetime\n","import os"]},{"cell_type":"code","source":["data_dir = pathlib.Path('drive/My Drive/TIES4911/task4/apparel-images-dataset')\n","image_count = len(list(data_dir.glob('*/*.jpg')))\n","print(image_count)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jMFd3eEQfZaN","executionInfo":{"status":"ok","timestamp":1677752589795,"user_tz":-120,"elapsed":2357,"user":{"displayName":"Trâm Mai","userId":"14047835568893253890"}},"outputId":"80a03a17-e1e5-41d4-a505-93f20e9d19d9"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["11385\n"]}]},{"cell_type":"code","source":["batch_size = 32\n","img_height = 224\n","img_width = 224"],"metadata":{"id":"yTy8R3TrM4L9","executionInfo":{"status":"ok","timestamp":1677752591987,"user_tz":-120,"elapsed":252,"user":{"displayName":"Trâm Mai","userId":"14047835568893253890"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["(train_ds, val_ds) = tf.keras.utils.image_dataset_from_directory(\n","    data_dir,\n","    shuffle=True,\n","    validation_split=0.2,\n","    subset='both',\n","    image_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    seed=123,\n","    label_mode='categorical'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u1HKOTcbg1k9","executionInfo":{"status":"ok","timestamp":1677741803678,"user_tz":-120,"elapsed":4595,"user":{"displayName":"Trâm Mai","userId":"14047835568893253890"}},"outputId":"741106c2-6373-43ec-9875-b3e7d93a3245"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 11385 files belonging to 24 classes.\n","Using 9108 files for training.\n","Using 2277 files for validation.\n"]}]},{"cell_type":"code","source":["class_names = train_ds.class_names\n","num_classes = len(class_names)\n","print(num_classes)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BAJmQEG4_eih","executionInfo":{"status":"ok","timestamp":1677741809681,"user_tz":-120,"elapsed":847,"user":{"displayName":"Trâm Mai","userId":"14047835568893253890"}},"outputId":"1aa4153a-71d2-44ee-8bb8-2f6b311a6277"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["24\n"]}]},{"cell_type":"code","source":["AUTOTUNE = tf.data.AUTOTUNE\n","\n","train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n","val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"],"metadata":{"id":"pVJSOctY_4sO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_augmentation = tf.keras.Sequential([\n","  tf.keras.layers.RandomFlip('horizontal'),\n","  tf.keras.layers.RandomRotation(0.2),\n","])"],"metadata":{"id":"7vesr4rW3hHS","executionInfo":{"status":"ok","timestamp":1677752933757,"user_tz":-120,"elapsed":227,"user":{"displayName":"Trâm Mai","userId":"14047835568893253890"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["inputs = Input(shape=(img_height, img_width, 3))\n","\n","base_model = mobilenet_v2.MobileNetV2(input_tensor=inputs)\n","base_model.trainable = False\n","preprocess_input = mobilenet_v2.preprocess_input\n","output_layer = layers.Dense(num_classes, activation='softmax')\n","\n","x = data_augmentation(inputs)\n","x = preprocess_input(x)\n","x = base_model(x, training=False)\n","outputs = output_layer(x)\n","\n","model = Model(inputs, outputs)\n","model.compile(\n","        loss=tf.keras.losses.CategoricalCrossentropy(),\n","        optimizer=tf.keras.optimizers.Adam(),\n","        metrics=[\"accuracy\"])\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ifB5sy2KAHJE","executionInfo":{"status":"ok","timestamp":1677752987283,"user_tz":-120,"elapsed":4429,"user":{"displayName":"Trâm Mai","userId":"14047835568893253890"}},"outputId":"fe18d8ab-fb0f-4f85-f021-d9bb0d00089d"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_4 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," sequential (Sequential)     (None, 224, 224, 3)       0         \n","                                                                 \n"," tf.math.truediv_2 (TFOpLamb  (None, 224, 224, 3)      0         \n"," da)                                                             \n","                                                                 \n"," tf.math.subtract_2 (TFOpLam  (None, 224, 224, 3)      0         \n"," bda)                                                            \n","                                                                 \n"," mobilenetv2_1.00_224 (Funct  (None, 1000)             3538984   \n"," ional)                                                          \n","                                                                 \n"," dense_2 (Dense)             (None, 24)                24024     \n","                                                                 \n","=================================================================\n","Total params: 3,563,008\n","Trainable params: 24,024\n","Non-trainable params: 3,538,984\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["checkpoint_path = 'drive/My Drive/TIES4911/task4/task4-3/checkpoint-{epoch:04d}'\n","checkpoint_dir = os.path.dirname(checkpoint_path)\n","latest = tf.train.latest_checkpoint(checkpoint_dir)\n","print(latest)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IJAUGxt0NJZj","executionInfo":{"status":"ok","timestamp":1677752990884,"user_tz":-120,"elapsed":830,"user":{"displayName":"Trâm Mai","userId":"14047835568893253890"}},"outputId":"8a4cf81a-960b-4863-d64b-7fcd6c77cea0"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["drive/My Drive/TIES4911/task4/task4-3/checkpoint-0020\n"]}]},{"cell_type":"code","source":["model.load_weights(latest)\n","model.evaluate(val_ds, verbose=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ygoFkdUgNjMV","executionInfo":{"status":"ok","timestamp":1677753102043,"user_tz":-120,"elapsed":108272,"user":{"displayName":"Trâm Mai","userId":"14047835568893253890"}},"outputId":"23b72f09-fcc8-4603-dd6f-9a2087b6a045"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.engine.functional.Functional object at 0x7fddaab80910> and <keras.layers.core.tf_op_layer.TFOpLambda object at 0x7fddaabf1280>).\n","WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.core.dense.Dense object at 0x7fddb8b7af10> and <keras.engine.functional.Functional object at 0x7fddaab80910>).\n","WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"]},{"output_type":"stream","name":"stdout","text":["72/72 - 105s - loss: 1.6342 - accuracy: 0.4717 - 105s/epoch - 1s/step\n"]},{"output_type":"execute_result","data":{"text/plain":["[1.6342331171035767, 0.47167325019836426]"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["stamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","logdir = 'drive/My Drive/TIES4911/task4/task4-3/logs/%s' % stamp\n","tensorboard = tf.keras.callbacks.TensorBoard(logdir)\n","\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_path,\n","    save_weights_only=True,\n","    save_freq=image_count // batch_size * 2,\n","    verbose=1)\n","\n","history = model.fit(train_ds,\n","                    epochs=30,\n","                    verbose=1,\n","                    initial_epoch=20,\n","                    validation_data=val_ds,\n","                    callbacks=[tensorboard, model_checkpoint_callback])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ovKSe-pVHJnD","outputId":"816b11b9-2017-4560-dc9c-2817c710c4a9","executionInfo":{"status":"ok","timestamp":1677759098943,"user_tz":-120,"elapsed":1248942,"user":{"displayName":"Trâm Mai","userId":"14047835568893253890"}}},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 21/30\n","285/285 [==============================] - 586s 2s/step - loss: 1.9924 - accuracy: 0.4111 - val_loss: 1.6207 - val_accuracy: 0.4752\n","Epoch 22/30\n","285/285 [==============================] - 581s 2s/step - loss: 1.9404 - accuracy: 0.4357 - val_loss: 1.6109 - val_accuracy: 0.4734\n","Epoch 23/30\n","139/285 [=============>................] - ETA: 3:45 - loss: 1.9068 - accuracy: 0.4432\n","Epoch 23: saving model to drive/My Drive/TIES4911/task4/task4-3/checkpoint-0023\n","285/285 [==============================] - 582s 2s/step - loss: 1.9081 - accuracy: 0.4429 - val_loss: 1.6020 - val_accuracy: 0.4717\n","Epoch 24/30\n","285/285 [==============================] - 537s 2s/step - loss: 1.8848 - accuracy: 0.4441 - val_loss: 1.5931 - val_accuracy: 0.4734\n","Epoch 25/30\n","279/285 [============================>.] - ETA: 9s - loss: 1.8656 - accuracy: 0.4574 \n","Epoch 25: saving model to drive/My Drive/TIES4911/task4/task4-3/checkpoint-0025\n","285/285 [==============================] - 586s 2s/step - loss: 1.8668 - accuracy: 0.4564 - val_loss: 1.5844 - val_accuracy: 0.4769\n","Epoch 26/30\n","285/285 [==============================] - 584s 2s/step - loss: 1.8353 - accuracy: 0.4598 - val_loss: 1.5757 - val_accuracy: 0.4805\n","Epoch 27/30\n","285/285 [==============================] - 539s 2s/step - loss: 1.8253 - accuracy: 0.4643 - val_loss: 1.5678 - val_accuracy: 0.4827\n","Epoch 28/30\n","134/285 [=============>................] - ETA: 3:53 - loss: 1.8028 - accuracy: 0.4747\n","Epoch 28: saving model to drive/My Drive/TIES4911/task4/task4-3/checkpoint-0028\n","285/285 [==============================] - 582s 2s/step - loss: 1.8094 - accuracy: 0.4695 - val_loss: 1.5606 - val_accuracy: 0.4879\n","Epoch 29/30\n","285/285 [==============================] - 534s 2s/step - loss: 1.7868 - accuracy: 0.4789 - val_loss: 1.5537 - val_accuracy: 0.4870\n","Epoch 30/30\n","274/285 [===========================>..] - ETA: 16s - loss: 1.7701 - accuracy: 0.4813\n","Epoch 30: saving model to drive/My Drive/TIES4911/task4/task4-3/checkpoint-0030\n","285/285 [==============================] - 580s 2s/step - loss: 1.7706 - accuracy: 0.4801 - val_loss: 1.5462 - val_accuracy: 0.4906\n"]}]},{"cell_type":"code","source":["model.evaluate(val_ds, verbose=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KDwIwooioeWq","executionInfo":{"status":"ok","timestamp":1677749099290,"user_tz":-120,"elapsed":108312,"user":{"displayName":"Trâm Mai","userId":"14047835568893253890"}},"outputId":"479f1571-79b7-4907-d32b-ae17710e0aab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["72/72 - 108s - loss: 1.6336 - accuracy: 0.4730 - 108s/epoch - 1s/step\n"]},{"output_type":"execute_result","data":{"text/plain":["[1.6336146593093872, 0.4729907810688019]"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["model.save(\"drive/My Drive/TIES4911/task4/task4-3/model\")"],"metadata":{"id":"HOqXbGooOyNk","executionInfo":{"status":"aborted","timestamp":1677753158779,"user_tz":-120,"elapsed":3,"user":{"displayName":"Trâm Mai","userId":"14047835568893253890"}}},"execution_count":null,"outputs":[]}]}